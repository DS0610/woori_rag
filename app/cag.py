# cag_cache.py
import re
import json
from collections import deque
from typing import List, Dict, Optional

import redis
import numpy as np
import pdfplumber
from sentence_transformers import SentenceTransformer
from redis.commands.search.field import TextField, VectorField
from redis.commands.search.index_definition import IndexDefinition, IndexType
from redis.commands.search.query import Query


class CAGCache:
    """
    âœ… CAG(ìºì‹œ ì¦ê°•) ì „ìš© ëª¨ë“ˆ
    - Redis + SentenceTransformer ê¸°ë°˜ ìºì‹œ ì¸ë±ìŠ¤
    - PDF â†’ Pre-Cache ì ì¬
    - ìºì‹œ ì¡°íšŒ(check_cache) + Dynamic Cache ì €ì¥
    """

    def __init__(
        self,
        redis_host: str = "localhost",
        redis_port: int = 6379,
        cache_index: str = "cache_index",
        model_name: str = "jhgan/ko-sroberta-multitask",
        dynamic_cache_size: int = 5,
        force_recreate_index: bool = False,
    ):
        # 1) Redis & ëª¨ë¸ ì´ˆê¸°í™”
        self.r = redis.Redis(
            host=redis_host,
            port=redis_port,
            decode_responses=False  # ì„ë² ë”©ì„ bytesë¡œ ì €ì¥í•´ì•¼ í•´ì„œ False ìœ ì§€
        )
        self.model = SentenceTransformer(model_name)
        self.CACHE_INDEX = cache_index
        self.user_cache = deque(maxlen=dynamic_cache_size)

        # 2) ì¸ë±ìŠ¤ ìƒì„±
        self._init_cache_index(force_recreate=force_recreate_index)

    # ------------------------------------------------------------
    # ì„ë² ë”© í•¨ìˆ˜ (ì •ê·œí™” ë¹„í™œì„±í™”: Redis COSINEê³¼ í˜¸í™˜)
    # ------------------------------------------------------------
    def _embed(self, text: str) -> bytes:
        emb = self.model.encode(text, normalize_embeddings=False)
        return np.array(emb, dtype=np.float32).tobytes()

    # ------------------------------------------------------------
    # ìºì‹œ ì¸ë±ìŠ¤ ì´ˆê¸°í™”
    # ------------------------------------------------------------
    def _init_cache_index(self, force_recreate: bool = True):
        if force_recreate:
            try:
                self.r.ft(self.CACHE_INDEX).dropindex(delete_documents=True)
                print(f"ğŸ—‘ï¸ ê¸°ì¡´ {self.CACHE_INDEX} ì¸ë±ìŠ¤ ì‚­ì œ ì™„ë£Œ")
            except Exception:
                pass

        try:
            self.r.ft(self.CACHE_INDEX).info()
            print(f"â„¹ï¸ {self.CACHE_INDEX} ì´ë¯¸ ì¡´ì¬ (ì¬ì‚¬ìš©)")
        except Exception:
            dim = len(self.model.encode("ì°¨ì› í™•ì¸", normalize_embeddings=False))
            self.r.ft(self.CACHE_INDEX).create_index(
                fields=[
                    VectorField("embedding", "FLAT", {
                        "TYPE": "FLOAT32",
                        "DIM": dim,
                        "DISTANCE_METRIC": "COSINE",
                    }),
                    TextField("text"),
                    TextField("source"),
                ],
                definition=IndexDefinition(
                    prefix=["cache:"],
                    index_type=IndexType.HASH,
                ),
            )
            print(f"âœ… {self.CACHE_INDEX} ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")

    # ------------------------------------------------------------
    # PDF Qâ€“A íŒŒì‹± (ë³¸ë¬¸ + í‘œ í¬í•¨)
    # ------------------------------------------------------------
    def extract_qa_pairs(self, pdf_path: str) -> List[Dict[str, str]]:
        qa_pairs: List[Dict[str, str]] = []
        with pdfplumber.open(pdf_path) as pdf:
            for page_idx, page in enumerate(pdf.pages):
                text = page.extract_text() or ""
                lines = text.split("\n") if text else []

                # í‘œ ì¶”ì¶œ
                tables = page.extract_tables()
                table_texts = []
                for table in tables:
                    rows = [
                        " | ".join([cell if cell else "" for cell in row])
                        for row in table
                    ]
                    table_texts.append("\n".join(rows))
                table_text_block = (
                    "\n\n[í‘œ ë°ì´í„°]\n" + "\n\n".join(table_texts)
                    if table_texts
                    else ""
                )

                merged_text = text + table_text_block

                current_q: Optional[str] = None
                current_a: List[str] = []

                for line in merged_text.split("\n"):
                    line = line.strip()
                    # ì§ˆë¬¸ íŒ¨í„´ (ë„¤ê°€ ì“°ë˜ ì •ê·œì‹ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
                    if re.match(
                        r".*(\?|ï¼Ÿ|ê¶ê¸ˆí•©ë‹ˆë‹¤\.?|ì•Œë ¤ì£¼ì„¸ìš”\.?|ë¬´ì—‡ì¸ê°€ìš”\.?|ì–´ë–»ê²Œ.*|ëŒ€í•´\s*ì„¤ëª….*|ìš”ì•½.*|ë¬¸ì˜(?:í•©ë‹ˆë‹¤|ë“œë¦½ë‹ˆë‹¤)\.?|ì„¤ëª…(?:í•´\s*ì£¼|í•˜ì—¬\s*ì£¼|ë°”ëë‹ˆë‹¤)\.?|ì•Œê³ \s*ì‹¶.*|ìš”ì²­(?:í•©ë‹ˆë‹¤|ë“œë¦½ë‹ˆë‹¤)\.?|ìœ ì˜ì‚¬í•­$|ì ˆì°¨$|ë°©ë²•$|ê¸°ì¤€$|ëŒ€ìƒ$|ìš”ê±´$|ì²˜ë¦¬$|ì‹ ê³ $|ìˆ˜ì…$|ìˆ˜ì¶œ$|ë°˜ì…$|ê²€ì‚¬$|í—ˆê°€$|í™•ì¸$|í†µê´€$)$",
                        line,
                    ):
                        if current_q and current_a:
                            qa_pairs.append(
                                {
                                    "question": current_q,
                                    "answer": "\n".join(current_a).strip(),
                                }
                            )
                        current_q = line
                        current_a = []
                    elif current_q:
                        current_a.append(line)

                if current_q and current_a:
                    qa_pairs.append(
                        {
                            "question": current_q,
                            "answer": "\n".join(current_a).strip(),
                        }
                    )

        return qa_pairs

    # ------------------------------------------------------------
    # Pre-Cache (PDF â†’ Redis ì €ì¥)
    # ------------------------------------------------------------
    def pre_cache_pdf(self, pdf_path: str):
        qa_list = self.extract_qa_pairs(pdf_path)
        print(f"ğŸ“˜ PDFì—ì„œ {len(qa_list)}ê°œì˜ QA ì¶”ì¶œ ì™„ë£Œ")

        for i, qa in enumerate(qa_list):
            key = f"cache:pdf:{i}"
            self.r.hset(
                key,
                mapping={
                    "embedding": self._embed(qa["question"]),
                    "text": qa["answer"],
                    "source": "pdf_pre_cache",
                },
            )
        print(f"ğŸ’¾ Redisì— {len(qa_list)}ê°œ Pre-Cache ì €ì¥ ì™„ë£Œ")

    # ------------------------------------------------------------
    # ìºì‹œ ê²€ìƒ‰ (CAG)
    # ------------------------------------------------------------
    def check_cache(
        self,
        user_query: str,
        k: int = 3,
        threshold: float = 0.7,
    ) -> Optional[str]:
        """
        - Redis ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ìœ ì‚¬ ì§ˆë¬¸ ì°¾ê¸°
        - sim >= threshold ì´ë©´ ìºì‹œ HIT, ì•„ë‹ˆë©´ MISS
        """
        q_emb = self._embed(user_query)
        q = (
            Query(f"*=>[KNN {k} @embedding $vec AS score]")
            .return_fields("text", "source", "score")
            .sort_by("score")
            .dialect(2)
        )

        try:
            res = self.r.ft(self.CACHE_INDEX).search(q, query_params={"vec": q_emb})
        except Exception as e:
            print("âŒ ìºì‹œ ê²€ìƒ‰ ì˜¤ë¥˜:", e)
            return None

        if not res.docs:
            print("âŒ ìºì‹œì—ì„œ ìœ ì‚¬ ë¬¸ì„œ ì—†ìŒ")
            return None

        # Redis KNN ê²€ìƒ‰ì˜ scoreëŠ” ê±°ë¦¬ì´ë¯€ë¡œ, 1 - distanceë¡œ ìœ ì‚¬ë„ ì¶”ì •
        sim = 1 - float(res.docs[0].score)
        print(f"ğŸ“Š ìœ ì‚¬ë„ ì ìˆ˜: {sim:.2f}")
        if sim >= threshold:
            print(
                f"âš¡ ìºì‹œ HIT (ìœ ì‚¬ë„ {sim:.2f}) [source={res.docs[0].source}]"
            )
            return res.docs[0].text

        print(f"âŒ ìºì‹œ MISS (ìœ ì‚¬ë„ {sim:.2f} < {threshold})")
        return None

    # ------------------------------------------------------------
    # Dynamic Cache ì €ì¥ (ìµœê·¼ Nê°œ ìœ ì§€)
    # ------------------------------------------------------------
    def save_dynamic_cache(self, query: str, answer: str):
        key = f"cache:dyn:{abs(hash(query)) % (10**8)}"
        self.r.hset(
            key,
            mapping={
                "embedding": self._embed(query),
                "text": answer,
                "source": "dynamic_cache",
            },
        )
        self.user_cache.append(key)
        if len(self.user_cache) > self.user_cache.maxlen:
            oldest = self.user_cache.popleft()
            self.r.delete(oldest)
            print(f"ğŸ—‘ï¸ ì˜¤ë˜ëœ ìºì‹œ ì‚­ì œ: {oldest}")

        print(f"ğŸ’¾ Dynamic Cache ì €ì¥: {query[:30]}...")
